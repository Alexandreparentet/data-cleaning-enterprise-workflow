{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40afa865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Caminho base dos dados\n",
    "BASE_PATH = '/content/drive/MyDrive/dados/'\n",
    "\n",
    "# Arquivos a serem carregados\n",
    "files = [\n",
    "    'order_products.csv', 'orders.csv', 'products.csv', 'prices.csv', 'discounts.csv',\n",
    "    'special_prices.csv', 'users.csv', 'companies.csv', 'products_approval.csv', 'homologated_products.csv'\n",
    "]\n",
    "\n",
    "# Carrega os datasets em um dict\n",
    "datasets = {f.split('.')[0]: pd.read_csv(BASE_PATH + f) for f in files}\n",
    "\n",
    "# Função para exibir informações gerais e valores nulos\n",
    "def explorar(df, nome):\n",
    "    print(f'\\n--- {nome} ---')\n",
    "    print(df.info())\n",
    "    display(df.describe())\n",
    "    display(df.isnull().sum())\n",
    "\n",
    "# Explorar dados iniciais\n",
    "for name, df in datasets.items():\n",
    "    explorar(df, name)\n",
    "\n",
    "# Colunas a remover por dataset\n",
    "cols_to_drop = {\n",
    "    'order_products': ['delivery_date'],\n",
    "    'orders': ['subsidiary_id', 'seller_id'],\n",
    "    'products': ['name', 'description', 'image_url'],\n",
    "    'prices': ['expiration_date'],\n",
    "    'users': ['encrypted_password', 'reset_password_token', 'reset_password_sent_at', 'remember_created_at', 'resume'],\n",
    "    'products_approval': ['name', 'description']\n",
    "}\n",
    "\n",
    "# Remover colunas desnecessárias\n",
    "for name, cols in cols_to_drop.items():\n",
    "    datasets[name].drop(columns=cols, inplace=True, errors='ignore')\n",
    "\n",
    "# Separar colunas de data e hora\n",
    "def processar_datas(df, cols):\n",
    "    for col in cols:\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors='coerce').dt.floor('s')\n",
    "            df[f'{col}_date'] = df[col].dt.floor('D')\n",
    "            df[f'{col}_hour'] = df[col] - df[col].dt.floor('D')\n",
    "            df.drop(columns=col, inplace=True)\n",
    "    return df\n",
    "\n",
    "# Definir colunas de datas para cada dataset\n",
    "date_columns = {\n",
    "    'order_products': ['price_date', 'created_at', 'updated_at'],\n",
    "    'orders': ['order_date', 'created_at', 'updated_at'],\n",
    "    'products': ['created_at', 'updated_at'],\n",
    "    'prices': ['created_at', 'updated_at'],\n",
    "    'discounts': ['created_at', 'updated_at'],\n",
    "    'special_prices': ['created_at', 'updated_at'],\n",
    "    'users': ['created_at', 'updated_at'],\n",
    "    'companies': ['created_at', 'updated_at'],\n",
    "    'products_approval': ['created_at', 'updated_at'],\n",
    "    'homologated_products': ['created_at', 'updated_at'],\n",
    "}\n",
    "\n",
    "# Aplicar processamento de datas\n",
    "for name, cols in date_columns.items():\n",
    "    datasets[name] = processar_datas(datasets[name], cols)\n",
    "\n",
    "# Renomear colunas\n",
    "rename_maps = {\n",
    "    'order_products': {\n",
    "        'order_id': 'id_pedido',\n",
    "        'supplier_product_id': 'id_produto_fornecedor',\n",
    "        'price_id': 'id_preco',\n",
    "        'price_value': 'valor_do_preco',\n",
    "        'quantity': 'quantidade',\n",
    "        'total_price': 'preco_total',\n",
    "        'price_date_date': 'data_preco',\n",
    "        'price_date_hour': 'hora_preco',\n",
    "        'created_at_date': 'data_criacao',\n",
    "        'created_at_hour': 'hora_criacao',\n",
    "        'updated_at_date': 'data_da_atualizacao',\n",
    "        'updated_at_hour': 'hora_da_atualizacao'\n",
    "    },\n",
    "    'orders': {\n",
    "        'company_id': 'id_empresa',\n",
    "        'user_id': 'id_usuario',\n",
    "        'order_value': 'valor_do_pedido',\n",
    "        'supplier_company_id': 'id_empresa_fornecedora',\n",
    "        'order_date_date': 'data_pedido',\n",
    "        'order_date_hour': 'hora_pedido',\n",
    "        'created_at_date': 'data_criacao',\n",
    "        'created_at_hour': 'hora_criacao',\n",
    "        'updated_at_date': 'data_da_atualizacao',\n",
    "        'updated_at_hour': 'hora_da_atualizacao'\n",
    "    },\n",
    "    # Adicione outros dicionários de renomeação conforme necessário...\n",
    "}\n",
    "\n",
    "for name, mapping in rename_maps.items():\n",
    "    datasets[name].rename(columns=mapping, inplace=True)\n",
    "\n",
    "# Tratar valores ausentes específicos\n",
    "if 'cpf' in datasets['users'].columns:\n",
    "    datasets['users']['cpf'] = datasets['users']['cpf'].fillna(0)\n",
    "\n",
    "# One-Hot Encoding em colunas categóricas específicas\n",
    "one_hot_cols = {\n",
    "    'orders': ['status'],\n",
    "    'prices': ['tipo_preco'],\n",
    "    'companies': ['tipo_empresa'],\n",
    "    'products_approval': ['status_atual']\n",
    "}\n",
    "\n",
    "def aplicar_one_hot(df, cols):\n",
    "    df = pd.get_dummies(df, columns=cols)\n",
    "    for col in df.columns:\n",
    "        if any(col.startswith(prefix + '_') for prefix in cols):\n",
    "            df[col] = df[col].astype(int)\n",
    "    return df\n",
    "\n",
    "for name, cols in one_hot_cols.items():\n",
    "    datasets[name] = aplicar_one_hot(datasets[name], cols)\n",
    "\n",
    "# Imputar valores numéricos ausentes com mediana\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "for name, cols in {\n",
    "    'prices': ['id_produto_fornecedor'],\n",
    "    'homologated_products': ['valor_ultima_compra', 'quantidade_ultima_compra']\n",
    "}.items():\n",
    "    datasets[name][cols] = imputer.fit_transform(datasets[name][cols])\n",
    "\n",
    "# Ajustar tipos para merge (exemplos)\n",
    "int_columns = {\n",
    "    'order_products': ['valor_do_preco', 'preco_total'],\n",
    "    'orders': ['valor_do_pedido'],\n",
    "    'prices': ['id_produto_fornecedor'],\n",
    "    'homologated_products': ['valor_ultima_compra', 'quantidade_ultima_compra']\n",
    "}\n",
    "for name, cols in int_columns.items():\n",
    "    for col in cols:\n",
    "        if col in datasets[name].columns:\n",
    "            datasets[name][col] = datasets[name][col].astype(int)\n",
    "\n",
    "# Converter datas em homologated_products e preencher NaT\n",
    "datasets['homologated_products']['data_ultima_compra'] = pd.to_datetime(\n",
    "    datasets['homologated_products'].get('data_ultima_compra', pd.NaT), errors='coerce'\n",
    ").fillna(pd.Timestamp('1900-01-01'))\n",
    "\n",
    "# Mostrar amostra final dos datasets processados\n",
    "for name, df in datasets.items():\n",
    "    print(f'\\nDataset: {name}')\n",
    "    display(df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
